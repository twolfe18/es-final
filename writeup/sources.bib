
@InProceedings{rami,
  author    = {Al-Rfou', Rami  and  Perozzi, Bryan  and  Skiena, Steven},
  title     = {Polyglot: Distributed Word Representations for Multilingual NLP},
  booktitle = {Proceedings of the Seventeenth Conference on Computational Natural Language Learning},
  month     = {August},
  year      = {2013},
  address   = {Sofia, Bulgaria},
  publisher = {Association for Computational Linguistics},
  pages     = {183--192}, 
  url       = {http://www.aclweb.org/anthology/W13-3520}
}

@Article{Hornik:1989,
 author = {Hornik, K. and Stinchcombe, M. and White, H.},
 title = {Multilayer Feedforward Networks Are Universal Approximators},
 journal = {Neural Netw.},
 issue_date = {1989},
 volume = {2},
 number = {5},
 month = jul,
 year = {1989},
 issn = {0893-6080},
 pages = {359--366},
 numpages = {8},
 url = {http://dx.doi.org/10.1016/0893-6080(89)90020-8},
 doi = {10.1016/0893-6080(89)90020-8},
 acmid = {70408},
 publisher = {Elsevier Science Ltd.},
 address = {Oxford, UK, UK},
} 

@InProceedings{agiga,
  author    = {Napoles, Courtney and Gormley, Matthew and {Van Durme}, Benjamin},
  title     = {Annotated Gigaword},
  booktitle = {AKBC-WEKEX Workshop at NAACL 2012},
  month     = {June},
  year      = {2012},
}

@InProceedings{theano,
     author = {Bergstra, James and Breuleux, Olivier and Bastien, Fr{\'{e}}d{\'{e}}ric and Lamblin, Pascal and Pascanu, Razvan and Desjardins, Guillaume and Turian, Joseph and Warde-Farley, David and Bengio, Yoshua},
      month = jun,
      title = {Theano: a {CPU} and {GPU} Math Expression Compiler},
  booktitle = {Proceedings of the Python for Scientific Computing Conference ({SciPy})},
       year = {2010},
   location = {Austin, TX},
       note = {Oral Presentation},
   abstract = {Theano is a compiler for mathematical expressions in Python that combines the convenience of NumPyâ€™s syntax with the speed of optimized native machine language. The user composes mathematical expressions in a high-level description that mimics NumPyâ€™s syntax and semantics, while being statically typed and
functional (as opposed to imperative). These expressions allow Theano to provide symbolic differentiation. Before performing computation, Theano optimizes the choice of expressions, translates
them into C++ (or CUDA for GPU), compiles them into dynamically loaded Python modules, all automatically. Common machine learning algorithms implemented with Theano are from 1.6Ã— to 7.5Ã— faster than competitive alternatives (including those implemented with C/C++, NumPy/SciPy and MATLAB) when compiled for the
CPU and between 6.5Ã— and 44Ã— faster when compiled for the GPU. This paper illustrates how to use Theano, outlines the scope of the compiler, provides benchmarks on both CPU and GPU processors, and explains its overall design.}
}

@Article{adagrad,
 author = {Duchi, John and Hazan, Elad and Singer, Yoram},
 title = {Adaptive Subgradient Methods for Online Learning and Stochastic Optimization},
 journal = {J. Mach. Learn. Res.},
 issue_date = {2/1/2011},
 volume = {12},
 month = jul,
 year = {2011},
 issn = {1532-4435},
 pages = {2121--2159},
 numpages = {39},
 url = {http://dl.acm.org/citation.cfm?id=1953048.2021068},
 acmid = {2021068},
 publisher = {JMLR.org},
} 

@article{pos,
 author = {Merialdo, Bernard},
 title = {Tagging English Text with a Probabilistic Model},
 journal = {Comput. Linguist.},
 issue_date = {June 1994},
 volume = {20},
 number = {2},
 month = jun,
 year = {1994},
 issn = {0891-2017},
 pages = {155--171},
 numpages = {17},
 url = {http://dl.acm.org/citation.cfm?id=972525.972526},
 acmid = {972526},
 publisher = {MIT Press},
 address = {Cambridge, MA, USA},
} 



